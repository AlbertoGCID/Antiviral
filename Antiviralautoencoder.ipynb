{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a505c98",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/AlbertoGCID/Antiviral/blob/main/Antiviralautoencoder.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9525c8",
   "metadata": {},
   "source": [
    "# Código extraído del trabajo de Adriana Anido Alonso\n",
    "## https://github.com/adrania/COVID19-Drugs-repurposing/blob/main/Mordred_ML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff267d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.chdir(path)\n",
    "import time\n",
    "import pyqsar\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Descriptors\n",
    "from pandas import read_csv\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "#Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier, RandomTreesEmbedding\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf6aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRdkitFeatures (descriptors, data):\n",
    "    '''Gives a table of features from a smile. Descriptor's list is given by the user.'''\n",
    "\n",
    "    calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptors) # first it creates a calculator object with the descriptors\n",
    "    #print(calculator.GetDescriptorSummaries()) # if we want to get a calculator summary\n",
    "    values = [] # creates a list to append each value\n",
    "    \n",
    "    for smile in data.smiles:\n",
    "        mol = Chem.MolFromSmiles(smile) # it creates a rdkit molecule object for each smile data\n",
    "        if mol is None: continue\n",
    "        desc = calculator.CalcDescriptors(mol) # generates a tuple with the features for each smile\n",
    "        values.append(desc) # it accumulates each tuple in a list\n",
    "        features = pd.DataFrame(values, columns = descriptors) # transform the list into a dataframe\n",
    "    \n",
    "    return features\n",
    "\n",
    "def ProcessData(i):\n",
    "    '''Replace not float values with NaN.'''\n",
    "    try: \n",
    "        return float(i)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def GetColumns (data):\n",
    "    '''Gets those columns with a percentage of cells with NaN values >= 50%.'''\n",
    "    columns = []\n",
    "    for col in data:\n",
    "        percent = data[col].isnull().sum()/data[col].isnull().count()\n",
    "        if percent >= 0.5:\n",
    "            columns.append(col)\n",
    "    return columns\n",
    "\n",
    "def ML_score (models, X_train, Y_train, X_test, Y_test, seed, classes = ['0','1']):\n",
    "    '''Fit diferent models, predict and return models' scores'''\n",
    "    ACC = 0\n",
    "    AUROC = 0\n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    \n",
    "    model_name = type(models).__name__ # get model name\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train different models using cross validation \n",
    "    print('> Training time: %0.2f mins'% ((time.time()-start_time)/60))\n",
    "        \n",
    "    models.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = models.predict(X_test)\n",
    "    y_probs = models.predict_proba(X_test)[:, 1]\n",
    "    model_report = classification_report(Y_test, y_pred, target_names=classes, output_dict=True, digits=3)\n",
    "     \n",
    "    # Scores\n",
    "    ACC = accuracy_score(Y_test, y_pred)\n",
    "    AUROC = roc_auc_score(Y_test, y_probs)\n",
    "    precision = model_report['weighted avg']['precision']\n",
    "    recall = model_report['weighted avg']['recall']\n",
    "    f1score = model_report['weighted avg']['f1-score']\n",
    "    \n",
    "    return ACC, AUROC, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ed38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "antiv = read_csv('antivirals_SMILES.csv')\n",
    "drugs = read_csv('DB_SMILES4prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ccbc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get RDKIT descriptors from smiles\n",
    "des_list = [x[0] for x in Descriptors._descList] # get all rdkit posible descriptors\n",
    "\n",
    "antiv_rdkit = pd.concat([antiv, GetRdkitFeatures(des_list, antiv)], axis=1)\n",
    "drugs_rdkit = pd.concat([drugs, GetRdkitFeatures(des_list, drugs)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save descriptors \n",
    "antiv_rdkit.to_csv('antiv_rdkit.csv', index_label=False)\n",
    "drugs_rdkit.to_csv('drugs_rdkit.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cef71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature datasets\n",
    "antiv_rdkit = read_csv('antiv_rdkit.csv', low_memory=False) #to solve different column types\n",
    "antiv = antiv_rdkit.copy() # train\n",
    "\n",
    "drugs_rdkit = read_csv('drugs_rdkit.csv', low_memory=False) #to solve different column types\n",
    "drugs = drugs_rdkit.copy() # predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d097014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ids and features\n",
    "a = antiv.iloc[:,2:]\n",
    "id_a = antiv.loc[:,:'Class']\n",
    "\n",
    "d = drugs.iloc[:,3:]\n",
    "id_d = drugs.loc[:,:'Class']\n",
    "\n",
    "# Replace different column types with NaN values\n",
    "a = a.applymap(ProcessData)\n",
    "d = d.applymap(ProcessData)\n",
    "\n",
    "# Restore datasets\n",
    "antiv = pd.concat([id_a, a], axis=1)\n",
    "drugs = pd.concat([id_d, d], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb322a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aproximation: any NaN value?\n",
    "print('Has Antivirals dataset NaN values?', antiv.isnull().values.any()) #true\n",
    "print('>> Columns with NaN: ', antiv.isnull().any().sum(), ' / ', len(antiv.columns))\n",
    "print('>> Number of data points with NaN: ', antiv.isnull().any(axis=1).sum(), ' / ', len(antiv))\n",
    "print('>> Number of rows with all NaN values: ', antiv.loc[:,'MaxEStateIndex':].isnull().all(axis=1).sum())\n",
    "\n",
    "print('\\nHas Drugs dataset NaN values?', drugs.isnull().values.any()) #true\n",
    "print('>> Columns with NaN: ', drugs.isnull().any().sum(), ' / ', len(drugs.columns))\n",
    "print('>> Number of data points with NaN: ', drugs.isnull().any(axis=1).sum(), ' / ', len(drugs))\n",
    "print('>> Number of rows with all NaN values: ', drugs.loc[:,'MaxEStateIndex':].isnull().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cf886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 8 rows with all NaN values in drugs dataset\n",
    "all_NA = [10246,10247,10248,10249,10250,10251,10252,10253] # all nan values from 10246 till 10253\n",
    "drugs = drugs.drop(all_NA) # remove 8 drugs from the drug dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b394342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select columns to drop from antivirals dataset\n",
    "to_drop = GetColumns(antiv)\n",
    "\n",
    "# Drop the same columns in each dataset\n",
    "antiv.drop(to_drop, axis=1, inplace=True) #same columns are removed\n",
    "drugs.drop(to_drop, axis=1, inplace=True) #same columns are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a32a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second aproximation \n",
    "print('Has Antivirals NaN values?', antiv.isnull().values.any()) #false\n",
    "print('Has Drugs NaN values?', drugs.isnull().values.any()) #true\n",
    "\n",
    "# Replace any NaN value with 0\n",
    "antiv = antiv.fillna(0)\n",
    "drugs = drugs.fillna(0)\n",
    "\n",
    "print('Has Antivirals NaN values?', antiv.isnull().values.any()) #false\n",
    "print('Has Drugs NaN values?', drugs.isnull().values.any()) #false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed files\n",
    "antiv.to_csv('antiv_prepro_rdkit.csv', index_label=False)\n",
    "drugs.to_csv('drugs_prepro_rdkit.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24368647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "input_data = read_csv('archivos/antiv_prepro_rdkit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0ae3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove smiles from dataset\n",
    "input_data = input_data.loc[:,'Class':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd404be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset samples: 229\n",
      "Train dataset samples: 183\n",
      "Test dataset samples: 46\n"
     ]
    }
   ],
   "source": [
    "# Set categoricals\n",
    "input_data['Class'] = pd.Categorical(input_data['Class'])\n",
    "\n",
    "# Train and test dataset, one split 0.8 train, 0.2 test. Random_state=80\n",
    "x = input_data[input_data.iloc[:,1:].columns] \n",
    "y = input_data['Class']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size=0.2, random_state=80)\n",
    "\n",
    "print('Full dataset samples: {}'.format(input_data.shape[0]))\n",
    "print('Train dataset samples: {}'.format(x_train.shape[0]))\n",
    "print('Test dataset samples: {}'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f380b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data using only train set\n",
    "sc = StandardScaler().fit(x_train)\n",
    "sc.get_params();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8f04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)\n",
    "\n",
    "x_train_std.mean(axis=0);\n",
    "x_train_std.std(axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a84657ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform splits from arrays into DataFrames\n",
    "df_train = pd.DataFrame(x_train_std, columns=list(input_data.iloc[:,1:].columns))\n",
    "df_train['Class'] = y_train\n",
    "\n",
    "df_test = pd.DataFrame(x_test_std, columns=list(input_data.iloc[:,1:].columns))\n",
    "df_test['Class'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd134ca9",
   "metadata": {},
   "source": [
    "# HASTA AQUÍ EL CÓDIGO DEL TFG DE ADRIANA\n",
    "## A partir de aquí, parto de los CSV generados para generar el modelo con autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a0f62df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 209)\n",
      "(183, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039730</td>\n",
       "      <td>0.795004</td>\n",
       "      <td>0.039730</td>\n",
       "      <td>-0.347689</td>\n",
       "      <td>0.109341</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>-0.054600</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.116396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.243550</td>\n",
       "      <td>0.684399</td>\n",
       "      <td>0.243550</td>\n",
       "      <td>-0.507950</td>\n",
       "      <td>1.475144</td>\n",
       "      <td>-1.037036</td>\n",
       "      <td>-1.086733</td>\n",
       "      <td>-1.035403</td>\n",
       "      <td>-0.776706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.639337</td>\n",
       "      <td>0.296942</td>\n",
       "      <td>0.639337</td>\n",
       "      <td>-0.601503</td>\n",
       "      <td>-0.752071</td>\n",
       "      <td>0.824439</td>\n",
       "      <td>0.930773</td>\n",
       "      <td>0.821683</td>\n",
       "      <td>0.652258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512692</td>\n",
       "      <td>0.655023</td>\n",
       "      <td>0.512692</td>\n",
       "      <td>-0.683701</td>\n",
       "      <td>-1.193726</td>\n",
       "      <td>1.446045</td>\n",
       "      <td>1.531216</td>\n",
       "      <td>1.447521</td>\n",
       "      <td>1.411394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123440</td>\n",
       "      <td>0.771337</td>\n",
       "      <td>0.123440</td>\n",
       "      <td>-0.609176</td>\n",
       "      <td>1.024848</td>\n",
       "      <td>-0.999173</td>\n",
       "      <td>-1.165782</td>\n",
       "      <td>-0.997665</td>\n",
       "      <td>-0.598086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxEStateIndex  MinEStateIndex  MaxAbsEStateIndex  MinAbsEStateIndex  \\\n",
       "0        0.039730        0.795004           0.039730          -0.347689   \n",
       "1        0.243550        0.684399           0.243550          -0.507950   \n",
       "2        0.639337        0.296942           0.639337          -0.601503   \n",
       "3        0.512692        0.655023           0.512692          -0.683701   \n",
       "4        0.123440        0.771337           0.123440          -0.609176   \n",
       "\n",
       "        qed     MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0  0.109341  0.012647       -0.054600    0.013548             0.116396   \n",
       "1  1.475144 -1.037036       -1.086733   -1.035403            -0.776706   \n",
       "2 -0.752071  0.824439        0.930773    0.821683             0.652258   \n",
       "3 -1.193726  1.446045        1.531216    1.447521             1.411394   \n",
       "4  1.024848 -0.999173       -1.165782   -0.997665            -0.598086   \n",
       "\n",
       "   NumRadicalElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                  0.0  ...    2.258318     -0.433949    -0.25289   \n",
       "1                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "2                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "3                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "4                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "1                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "2                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "3                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "4                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0         -0.100082      0.0  \n",
       "1         -0.100082      0.0  \n",
       "2         -0.100082      0.0  \n",
       "3         -0.100082      0.0  \n",
       "4         -0.100082      0.0  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "#183 muestras con 209 características\n",
    "# pero este dataset tiene las etiquetas\n",
    "# para la seleccion de características me quedo únicamente con las variables sin la etiqueta (que es la última)\n",
    "df_train_se = df_train.iloc[:,:-1]\n",
    "df_train_e = df_train.iloc[:,-1]\n",
    "print(df_train_se.shape)\n",
    "df_train_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "065dcad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 209)\n",
      "(46, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.159864</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.115840</td>\n",
       "      <td>-1.730217</td>\n",
       "      <td>1.962905</td>\n",
       "      <td>1.808900</td>\n",
       "      <td>1.964641</td>\n",
       "      <td>2.259842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.280431</td>\n",
       "      <td>0.846388</td>\n",
       "      <td>-0.280431</td>\n",
       "      <td>-0.581039</td>\n",
       "      <td>1.390979</td>\n",
       "      <td>-1.128080</td>\n",
       "      <td>-1.284822</td>\n",
       "      <td>-1.126545</td>\n",
       "      <td>-0.732051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.625427</td>\n",
       "      <td>0.335273</td>\n",
       "      <td>0.625427</td>\n",
       "      <td>-0.190117</td>\n",
       "      <td>-0.619942</td>\n",
       "      <td>0.471647</td>\n",
       "      <td>0.500352</td>\n",
       "      <td>0.472996</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442807</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106775</td>\n",
       "      <td>0.798175</td>\n",
       "      <td>0.106775</td>\n",
       "      <td>0.114934</td>\n",
       "      <td>-0.293715</td>\n",
       "      <td>0.141554</td>\n",
       "      <td>0.064440</td>\n",
       "      <td>0.142428</td>\n",
       "      <td>0.250361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.431360</td>\n",
       "      <td>1.321082</td>\n",
       "      <td>-3.431360</td>\n",
       "      <td>3.006597</td>\n",
       "      <td>-0.423819</td>\n",
       "      <td>-0.070274</td>\n",
       "      <td>-0.034134</td>\n",
       "      <td>-0.070138</td>\n",
       "      <td>-0.240845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.258318</td>\n",
       "      <td>-0.433949</td>\n",
       "      <td>-0.25289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.240869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.311645</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxEStateIndex  MinEStateIndex  MaxAbsEStateIndex  MinAbsEStateIndex  \\\n",
       "0        0.696203        0.159864           0.696203           0.115840   \n",
       "1       -0.280431        0.846388          -0.280431          -0.581039   \n",
       "2        0.625427        0.335273           0.625427          -0.190117   \n",
       "3        0.106775        0.798175           0.106775           0.114934   \n",
       "4       -3.431360        1.321082          -3.431360           3.006597   \n",
       "\n",
       "        qed     MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0 -1.730217  1.962905        1.808900    1.964641             2.259842   \n",
       "1  1.390979 -1.128080       -1.284822   -1.126545            -0.732051   \n",
       "2 -0.619942  0.471647        0.500352    0.472996             0.518292   \n",
       "3 -0.293715  0.141554        0.064440    0.142428             0.250361   \n",
       "4 -0.423819 -0.070274       -0.034134   -0.070138            -0.240845   \n",
       "\n",
       "   NumRadicalElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "1                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "2                  0.0  ...   -0.442807     -0.433949    -0.25289   \n",
       "3                  0.0  ...    2.258318     -0.433949    -0.25289   \n",
       "4                  0.0  ...    2.258318     -0.433949    -0.25289   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "1                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "2                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "3                0.0           0.0    -0.227429          0.0     -0.311645   \n",
       "4                0.0           0.0     3.240869          0.0     -0.311645   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0         -0.100082      0.0  \n",
       "1         -0.100082      0.0  \n",
       "2         -0.100082      0.0  \n",
       "3         -0.100082      0.0  \n",
       "4         -0.100082      0.0  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test_se = df_test.iloc[:,:-1] \n",
    "df_test_e = df_test.iloc[:,-1] \n",
    "print(df_test_se.shape)\n",
    "df_test_se.head()\n",
    "#46 muestras con 209 características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af50014",
   "metadata": {},
   "source": [
    "Los datos que ella utiliza no están entre 0 y 1, lo que podría ser un problema a la hora de reconstruirlos, primero vamos a aumentar los datos añadiendo ruido a las muestras. Este ruido se añadirá a todas las muestras por igual, no sabemos si esto va a afectar a las etiquetas, es posible que al modificar los parámetros de una muestra esta debería cambiar de etiqueta pero esto nos será indiferente si conseguimos reconstruir bien el conjunto de test, después vamos a normalizar los datos usando min-max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e1c42349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639940</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224977</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.934013</td>\n",
       "      <td>0.874411</td>\n",
       "      <td>0.935702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833596</td>\n",
       "      <td>0.852811</td>\n",
       "      <td>0.833596</td>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.851843</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.171385</td>\n",
       "      <td>0.208116</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.987941</td>\n",
       "      <td>0.694329</td>\n",
       "      <td>0.987941</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.323937</td>\n",
       "      <td>0.583660</td>\n",
       "      <td>0.577053</td>\n",
       "      <td>0.584607</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.837862</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.224734</td>\n",
       "      <td>0.409578</td>\n",
       "      <td>0.506109</td>\n",
       "      <td>0.477995</td>\n",
       "      <td>0.506800</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.296724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.296724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375423</td>\n",
       "      <td>0.456343</td>\n",
       "      <td>0.455595</td>\n",
       "      <td>0.456768</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MaxEStateIndex  MinEStateIndex  MaxAbsEStateIndex  MinAbsEStateIndex  \\\n",
       "0        1.000000        0.639940           1.000000           0.224977   \n",
       "1        0.833596        0.852811           0.833596           0.038141   \n",
       "2        0.987941        0.694329           0.987941           0.142949   \n",
       "3        0.899570        0.837862           0.899570           0.224734   \n",
       "4        0.296724        1.000000           0.296724           1.000000   \n",
       "\n",
       "        qed     MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0  0.032468  0.934013        0.874411    0.935702             1.000000   \n",
       "1  0.851843  0.207824        0.171385    0.208116             0.287234   \n",
       "2  0.323937  0.583660        0.577053    0.584607             0.585106   \n",
       "3  0.409578  0.506109        0.477995    0.506800             0.521277   \n",
       "4  0.375423  0.456343        0.455595    0.456768             0.404255   \n",
       "\n",
       "   NumRadicalElectrons  ...    fr_sulfide  fr_sulfonamd    fr_sulfone  \\\n",
       "0         1.000000e-10  ...  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "1         1.000000e-10  ...  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "2         1.000000e-10  ...  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "3         1.000000e-10  ...  5.000000e-01  1.000000e-10  1.000000e-10   \n",
       "4         1.000000e-10  ...  5.000000e-01  1.000000e-10  1.000000e-10   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole   fr_thiazole   fr_thiocyan  fr_thiophene  \\\n",
       "0       1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "1       1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "2       1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "3       1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10  1.000000e-10   \n",
       "4       1.000000e-10  1.000000e-10  3.333333e-01  1.000000e-10  1.000000e-10   \n",
       "\n",
       "   fr_unbrch_alkane       fr_urea  \n",
       "0      1.000000e-10  1.000000e-10  \n",
       "1      1.000000e-10  1.000000e-10  \n",
       "2      1.000000e-10  1.000000e-10  \n",
       "3      1.000000e-10  1.000000e-10  \n",
       "4      1.000000e-10  1.000000e-10  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_noise(df):\n",
    "    noised_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        noised_row = row + np.random.normal(loc=0, scale=0.2, size=len(row))\n",
    "        noised_row2 = row - np.random.normal(loc=0, scale=0.2, size=len(row))\n",
    "        noised_rows.append(noised_row)\n",
    "        noised_rows.append(noised_row2)\n",
    "        noised_row = row + np.random.normal(loc=0, scale=0.2, size=len(row))\n",
    "        noised_row2 = row - np.random.normal(loc=0, scale=0.2, size=len(row))\n",
    "        noised_rows.append(noised_row)\n",
    "        noised_rows.append(noised_row2)\n",
    "    noised_df = pd.concat([df, pd.DataFrame(noised_rows, columns=df.columns)], ignore_index=True)\n",
    "    return noised_df\n",
    "\n",
    "def min_max_scaling(df):\n",
    "    df_scaled = (df - df.min()) / (df.max() - df.min())\n",
    "    df_scaled = df_scaled.where((df_scaled >= 0), 0)\n",
    "    return df_scaled.where(~(df_scaled.eq(0).all(axis=0)), df_scaled + 1e-10)\n",
    "\n",
    "df_train_se_aug= add_noise(df_train_se)\n",
    "df_train_se_aug = min_max_scaling(df_train_se_aug)\n",
    "df_test_se = min_max_scaling(df_test_se)\n",
    "df_test_se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e3b21212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732, 208) (183, 208)\n"
     ]
    }
   ],
   "source": [
    "df_train_se_aug.shape\n",
    "train_df, val_df = train_test_split(df_train_se_aug, test_size=0.2)\n",
    "print(train_df.shape,val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae865d",
   "metadata": {},
   "source": [
    "## Creo el Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "39741f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, optimizers,losses\n",
    "from random import seed\n",
    "from matplotlib import pyplot\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed(90) # Fijamos una semilla para que las pruebas sean reproducibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "820816b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la entrada es un vector de (1x209)\n",
    "\n",
    "\n",
    "#TODO: modificar la arquitectura, añadir más capas\n",
    "\n",
    "def crearencoder(entradas,dimension,l2_value):\n",
    "    print(\"esto es l2 encoder\",l2_value,type(l2_value))\n",
    "    encoder = tf.keras.Sequential()\n",
    "    dim = entradas.shape[1] # cogemos el número de características\n",
    "    encoder.add(tf.keras.layers.InputLayer(dim))\n",
    "    encoder.add(tf.keras.layers.Dense(dim,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    encoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    encoder.add(tf.keras.layers.Dense(dim//1.5,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    encoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))  \n",
    "    encoder.add(tf.keras.layers.Dense(dim//2,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    encoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    encoder.add(tf.keras.layers.Dense(dim//3,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    encoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))  \n",
    "    encoder.add(tf.keras.layers.Dense(dim//4,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    encoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))  \n",
    "    encoder.add(tf.keras.layers.Dense(dimension,activation='softmax'))\n",
    "    encoder.build()\n",
    "    return encoder\n",
    "\n",
    "def creardecoder(entradas,dimension,l2_value):\n",
    "    dim = entradas.shape[1]\n",
    "    decoder = tf.keras.Sequential()\n",
    "    decoder.add(tf.keras.layers.InputLayer(dimension))  \n",
    "    decoder.add(tf.keras.layers.Dense(dim,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    decoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    decoder.add(tf.keras.layers.Dense(dim//4,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    decoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    decoder.add(tf.keras.layers.Dense(dim//3,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    decoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    decoder.add(tf.keras.layers.Dense(dim//2,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    decoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    decoder.add(tf.keras.layers.Dense(dim//1.5,activation='relu',kernel_regularizer=l2(l2_value)))\n",
    "    decoder.add(tf.keras.layers.BatchNormalization(axis=1,epsilon=0.001))\n",
    "    decoder.add(tf.keras.layers.Dense(dim,activation='linear'))\n",
    "    decoder.build()\n",
    "    return decoder\n",
    "\n",
    "def buildautoencoder(entradas,dimension,l2):\n",
    "    encoder = crearencoder(entradas,dimension,l2)\n",
    "    decoder = creardecoder(entradas,dimension,l2)\n",
    "    autoencoder = tf.keras.Sequential([encoder,decoder])\n",
    "    autoencoder.build(entradas.shape)\n",
    "    autoencoder.compile(loss=fn_perdida,optimizer='Adam',metrics=\"mse\")\n",
    "    return autoencoder,decoder,encoder\n",
    "\n",
    "def plottrain(historico):\n",
    "    pyplot.plot(historico.history['loss'], label='train')\n",
    "    pyplot.plot(historico.history['val_loss'], label='val')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    \n",
    "def probarmodelo(train,val,dimension,test,Epochs,batchs,l2):\n",
    "    modelocreado,decoder,encoder = buildautoencoder(train,dimension,l2)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "    historico = modelocreado.fit(train,train,validation_data=(val,val),shuffle=True,batch_size=batchs, epochs= Epochs,verbose=False, callbacks=[early_stop])\n",
    "    plottrain(historico)\n",
    "    epochs_done = early_stop.stopped_epoch + 1\n",
    "    latente = encoder.predict(test,verbose=False)\n",
    "    reconstruidos = decoder.predict(latente,verbose=False)\n",
    "    #ahora tengo que calcular la pérdida entre las entradas y los reconstuidos\n",
    "    return fn_perdida(test, reconstruidos),epochs_done,encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b3c2498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esto es l2 encoder 0.001 <class 'float'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [317]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dimension_h:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m l2:\n\u001b[0;32m----> 9\u001b[0m         precisiontest \u001b[38;5;241m=\u001b[39m \u001b[43mprobarmodelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_test_se\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatchs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl error con espacio latente \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m y \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m epochs de l2 \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m en test \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i,precisiontest[\u001b[38;5;241m1\u001b[39m],j,precisiontest[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "Input \u001b[0;32mIn [316]\u001b[0m, in \u001b[0;36mprobarmodelo\u001b[0;34m(train, val, dimension, test, Epochs, batchs, l2)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprobarmodelo\u001b[39m(train,val,dimension,test,Epochs,batchs,l2):\n\u001b[0;32m---> 58\u001b[0m     modelocreado,decoder,encoder \u001b[38;5;241m=\u001b[39m \u001b[43mbuildautoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m     historico \u001b[38;5;241m=\u001b[39m modelocreado\u001b[38;5;241m.\u001b[39mfit(train,train,validation_data\u001b[38;5;241m=\u001b[39m(val,val),shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,batch_size\u001b[38;5;241m=\u001b[39mbatchs, epochs\u001b[38;5;241m=\u001b[39m Epochs,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m[early_stop])\n",
      "Input \u001b[0;32mIn [316]\u001b[0m, in \u001b[0;36mbuildautoencoder\u001b[0;34m(entradas, dimension, l2)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuildautoencoder\u001b[39m(entradas,dimension,l2):\n\u001b[0;32m---> 44\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mcrearencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentradas\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m creardecoder(entradas,dimension,l2)\n\u001b[1;32m     46\u001b[0m     autoencoder \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([encoder,decoder])\n",
      "Input \u001b[0;32mIn [316]\u001b[0m, in \u001b[0;36mcrearencoder\u001b[0;34m(entradas, dimension, l2_value)\u001b[0m\n\u001b[1;32m      9\u001b[0m dim \u001b[38;5;241m=\u001b[39m entradas\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m# cogemos el número de características\u001b[39;00m\n\u001b[1;32m     10\u001b[0m encoder\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputLayer(dim))\n\u001b[0;32m---> 11\u001b[0m encoder\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(dim,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,kernel_regularizer\u001b[38;5;241m=\u001b[39m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml2_value\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     12\u001b[0m encoder\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n\u001b[1;32m     13\u001b[0m encoder\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1.5\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(l2_value)))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "#lo junto todo para probar parámetros\n",
    "dimension_h = [10,50]\n",
    "fn_perdida = tf.keras.losses.MeanSquaredError()\n",
    "Epochs = 500\n",
    "batchs = 32\n",
    "l2 = [1e-3,1e-5,1e-7]\n",
    "for i in dimension_h:\n",
    "    for j in l2:\n",
    "        precisiontest = probarmodelo(train_df,val_df,i,df_test_se,Epochs,batchs,j)\n",
    "        print(\"El error con espacio latente {} y {} epochs de l2 {} en test {:.2f} %\".format(i,precisiontest[1],j,precisiontest[0].numpy()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78b6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "25ad5299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.001\n"
     ]
    }
   ],
   "source": [
    "k = 1e-3 +1\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4801b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
